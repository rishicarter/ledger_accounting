{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install beyondllm"
      ],
      "metadata": {
        "id": "K_tIk-m9EGv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "id": "4_8cI-ihL0pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from beyondllm import source,retrieve,generator,embeddings,llms\n",
        "from getpass import getpass\n",
        "from beyondllm.vectordb import ChromaVectorDb\n",
        "\n",
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "LMSL6M1dbvC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AIzaSyDzJpCzonF2U7UQD90LgTWCakM3ay5PpZI - Google\n",
        "# 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 - HF\n",
        "\n",
        "hf_token = getpass(\"Enter HF Token: \")\n",
        "google_api_key = getpass(\"Enter Google Token: \")\n",
        "\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "os.environ['GOOGLE_API_KEY'] = google_api_key\n",
        "\n",
        "MODEL_NAME = \"BAAI/bge-small-en-v1.5\"#\"thenlper/gte-large\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLeLeaFlEYWI",
        "outputId": "f8949b9d-494a-469b-a6f8-8218ff4fa350"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter HF Token: ··········\n",
            "Enter Google Token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# excel_file = 'ledgers.xlsx'\n",
        "# csv_path = \"./data/\"\n",
        "\n",
        "# excel_data = pd.ExcelFile(excel_file)\n",
        "# sheet_names = excel_data.sheet_names\n",
        "\n",
        "# for sheet_name in sheet_names:\n",
        "#     df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
        "#     csv_file_name = f\"{csv_path + sheet_name}.csv\"\n",
        "#     df.to_csv(csv_file_name, index=False)\n",
        "\n",
        "#     print(f\"Saved {sheet_name} as {csv_file_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOHO_ZAIEihH",
        "outputId": "8d09b1b4-b0a9-463f-d0fa-d255330c1ae9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Ramesh chowdhary as ./data/Ramesh chowdhary.csv\n",
            "Saved Pranavni as ./data/Pranavni.csv\n",
            "Saved hdfc as ./data/hdfc.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = ChromaVectorDb(collection_name=\"my_persistent_collection\", persist_directory=\"./db/chroma/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odTmuC4wRhZc",
        "outputId": "6909a2a1-9ecf-4315-ecb5-0c828df2328b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The feature you're trying to use requires an additional library(s):llama_index.vector_stores.chroma. Would you like to install it now? [y/N]: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_paths = [\"/content/data/Pranavni.csv\", \"/content/data/Ramesh chowdhary.csv\",\n",
        "             \"/content/data/hdfc.csv\"]\n",
        "# embed_model = embeddings.HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embed_model = embeddings.GeminiEmbeddings(api_key=google_api_key,\n",
        "                                          model_name=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "voaqp_HDF4N0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = source.fit(path=csv_paths, dtype=\"csv\")\n",
        "retriever = retrieve.auto_retriever(\n",
        "    data=data,\n",
        "    embed_model=embed_model,\n",
        "    type=\"hybrid\",\n",
        "    top_k=5,\n",
        "    mode=\"OR\"\n",
        ")"
      ],
      "metadata": {
        "id": "jOsJyTzcEMrq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = llms.GeminiModel(model_name=\"gemini-pro\",\n",
        "                       google_api_key=google_api_key)"
      ],
      "metadata": {
        "id": "i1FHMauYQKNj"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"what amount paid to Ramesh Choupardu?\""
      ],
      "metadata": {
        "id": "i_27rw13PQ2E"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are an accountant, who answers questions based on the ledgers found in the csvs. Each ledger has date, the amount that was debited, type of payment cash or anything else. Based on the context answer the quesetion.\"\n",
        "pipeline = generator.Generate(question=question,\n",
        "                              retriever=retriever,\n",
        "                              llm=llm,\n",
        "                              system_prompt=system_prompt)\n",
        "response = pipeline.call()\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zyY3v6GPEMvf",
        "outputId": "da610368-b702-436b-e25d-67f2421ec27d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Embeddings have been explicitly disabled. Using MockEmbedding.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'21000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sOtpwO7iEM4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWRi7a8REM_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}